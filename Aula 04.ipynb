{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instituto Federal do Sudeste de Minas Gerais, Campus Barbacena\n",
    "### Projeto Laboratório de Redes de Conhecimento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curso de Mineração de Dados Aplicada\n",
    "\n",
    "Prof. Rafael José de Alencar Almeida\n",
    "<rafael.alencar@ifsudestemg.edu.br>\n",
    "\n",
    "<br>\n",
    "\n",
    "## Aula 4:  Processamento de Linguagem Natural\n",
    "\n",
    "#### \"Estima-se que 80% de todo conteúdo mundial online são textos\"\n",
    "_Chen, H. Knowledge management systems: a text mining perspective. Arizona: Knowledge\n",
    "Computing Corporation. 2001._\n",
    "\n",
    "#### \"No geral, 80% das informações criadas e utilizadas por uma empresa são dados não estruturados, o que torna a manipulação e interpretação mais complexa\".\n",
    "_André Pannunzio, PricewaterhouseCoopers (PwC) Brasil._\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://www.celebros.com/media/k2/items/cache/e0a70f72bdae9885bfc32d7cd19a26a1_L.jpg\">\n",
    "\n",
    "<strong>Linguagem Natural:</strong> meio de comunicação utilizado pelos humanos para se comunicarem (idiomas e línguas de sinais).\n",
    "\n",
    "<strong>Processamento de linguagem natural (PLN):</strong> subárea da ciência da computação, inteligência artificial e da linguística que estuda os problemas da geração e compreensão automática de línguas humanas naturais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: notícias IF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>titulo</th>\n",
       "      <th>conteudo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14/09/2017</td>\n",
       "      <td>Campus Barbacena divulga Resultado Provisório ...</td>\n",
       "      <td>\\n\\n\\tO Campus Barbacena divulgou o Resultado ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14/09/2017</td>\n",
       "      <td>Divulgado o Edital de convocação de assembleia...</td>\n",
       "      <td>\\n\\n\\tDivulgado o Edital de convocação de asse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14/09/2017</td>\n",
       "      <td>Pesquisador da Bélgica realiza palestra no Cam...</td>\n",
       "      <td>\\n\\n\\tO pesquisador da Bélgica, Luc Vankrunkel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14/09/2017</td>\n",
       "      <td>Divulgada a homologação das inscrições à candi...</td>\n",
       "      <td>\\n\\n\\tDivulgada a homologação das inscrições à...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14/09/2017</td>\n",
       "      <td>Aprovado Regulamento de Eventos, Cerimonial e ...</td>\n",
       "      <td>\\n\\n\\tO Regulamento, aprovado no dia 05 de set...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         data                                             titulo  \\\n",
       "0  14/09/2017  Campus Barbacena divulga Resultado Provisório ...   \n",
       "1  14/09/2017  Divulgado o Edital de convocação de assembleia...   \n",
       "2  14/09/2017  Pesquisador da Bélgica realiza palestra no Cam...   \n",
       "3  14/09/2017  Divulgada a homologação das inscrições à candi...   \n",
       "4  14/09/2017  Aprovado Regulamento de Eventos, Cerimonial e ...   \n",
       "\n",
       "                                            conteudo  \n",
       "0  \\n\\n\\tO Campus Barbacena divulgou o Resultado ...  \n",
       "1  \\n\\n\\tDivulgado o Edital de convocação de asse...  \n",
       "2  \\n\\n\\tO pesquisador da Bélgica, Luc Vankrunkel...  \n",
       "3  \\n\\n\\tDivulgada a homologação das inscrições à...  \n",
       "4  \\n\\n\\tO Regulamento, aprovado no dia 05 de set...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('df_noticias_if.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data                                               14/09/2017\n",
       "titulo      Campus Barbacena divulga Resultado Provisório ...\n",
       "conteudo    \\n\\n\\tO Campus Barbacena divulgou o Resultado ...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\tO Campus Barbacena divulgou o Resultado Provisório do VIII Simpósio de Pesquisa e Inovação.\n",
      "\n",
      "\tOs estudantes devem ficar atentos as observações que constam no final do documento.\n",
      "\n",
      "Leia o documento\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0]['conteudo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processamento\n",
    "\n",
    "Consiste em processar os textos antes de realizar sua conversão para um formato numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\to campus barbacena divulgou o resultado provisório do viii simpósio de pesquisa e inovação.\\n\\n\\tos estudantes devem ficar atentos as observações que constam no final do documento.\\n\\nleia o documento\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conversão para minúsculas\n",
    "df.iloc[0]['conteudo'].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remoção de pontuação\n",
    "from string import punctuation\n",
    "\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\tO Campus Barbacena divulgou o Resultado Provisório do VIII Simpósio de Pesquisa e Inovação\\n\\n\\tOs estudantes devem ficar atentos as observações que constam no final do documento\\n\\nLeia o documento\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([l for l in df.iloc[0]['conteudo'] if l not in punctuation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O Campus Barbacena divulgou o Resultado Provisório do VIII Simpósio de Pesquisa e Inovação.Os estudantes devem ficar atentos as observações que constam no final do documento.Leia o documento'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substituição de caracteres\n",
    "df.iloc[0]['conteudo'].replace('\\n', '').replace('\\t', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O Campus Barbacena divulgou o Resultado Provisório do VIII Simpósio de Pesquisa e Inovação.Os estudantes devem ficar atentos as observações que constam no final do documento.Leia o documento'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substituição de caracteres com re\n",
    "import re\n",
    "\n",
    "re.sub(r'\\n|\\t', '', df.iloc[0]['conteudo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n\\n\\tO', 'Campus', 'Barbacena', 'divulgou', 'o', 'Resultado', 'Provisório', 'do', 'VIII', 'Simpósio', 'de', 'Pesquisa', 'e', 'Inovação.\\n\\n\\tOs', 'estudantes', 'devem', 'ficar', 'atentos', 'as', 'observações', 'que', 'constam', 'no', 'final', 'do', 'documento.\\n\\nLeia', 'o', 'documento\\n']\n"
     ]
    }
   ],
   "source": [
    "# Tokenização com split\n",
    "print(df.iloc[0]['conteudo'].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'Campus', 'Barbacena', 'divulgou', 'o', 'Resultado', 'Provisório', 'do', 'VIII', 'Simpósio', 'de', 'Pesquisa', 'e', 'Inovação', '.', 'Os', 'estudantes', 'devem', 'ficar', 'atentos', 'as', 'observações', 'que', 'constam', 'no', 'final', 'do', 'documento', '.', 'Leia', 'o', 'documento']\n"
     ]
    }
   ],
   "source": [
    "# Tokenização com nltk\n",
    "from nltk import word_tokenize\n",
    "\n",
    "print(word_tokenize(df.iloc[0]['conteudo']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n\\n\\tO Campus Barbacena divulgou o Resultado Provisorio do VIII Simposio de Pesquisa e Inovacao.\\n\\n\\tOs estudantes devem ficar atentos as observacoes que constam no final do documento.\\n\\nLeia o documento\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remoção de acentos\n",
    "from unicodedata import normalize\n",
    "\n",
    "normalize('NFKD', df.iloc[0]['conteudo']).encode('ASCII', 'ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'a', 'o', 'que', 'e', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
     ]
    }
   ],
   "source": [
    "# Remoção de stopwords\n",
    "# Palavras frequentes mas com pouco significado semântico\n",
    "import nltk\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['campus', 'barbacena', 'divulgou', 'resultado', 'provisório', 'viii', 'simpósio', 'pesquisa', 'inovação', 'estudantes', 'devem', 'ficar', 'atentos', 'observações', 'constam', 'final', 'documento', 'leia', 'documento']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in word_tokenize(df.iloc[0]['conteudo'].lower()) if (w not in stopwords) and (w not in punctuation)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('program', 'program', 'program')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming\n",
    "# Redução do termo a seu radical\n",
    "\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "\n",
    "stemmer.stem('programar'), stemmer.stem('programava'), stemmer.stem('programaremos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('car', 'box', 'spy', 'child')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization (EN)\n",
    "# Menos \"agressivo\" que o stemming\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "lmtzr.lemmatize('cars'), lmtzr.lemmatize('boxes'), lmtzr.lemmatize('spies'), lmtzr.lemmatize('children')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'DT'),\n",
       " ('book', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('table', 'NN')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parts of Speech Tagging (EN)\n",
    "nltk.pos_tag('the book is on the table'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    campus barbacena divulga resultado provisório ...\n",
       "1    divulgado edital convocação assembleia centro ...\n",
       "2    pesquisador bélgica realiza palestra campus ba...\n",
       "3    divulgada homologação inscrições candidatura c...\n",
       "4    aprovado regulamento eventos cerimonial protoc...\n",
       "Name: doc, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gerando uma coluna de texto pré-processado (título + conteúdo)\n",
    "def processa(row):\n",
    "    txt = row['titulo'] + ' ' + row['conteudo']\n",
    "    \n",
    "    return ' '.join([t for t in word_tokenize(txt.lower()) if (t not in stopwords) and (t not in punctuation)])\n",
    "\n",
    "df['doc'] = df.apply(processa, axis=1)\n",
    "\n",
    "df['doc'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vetorização\n",
    "\n",
    "Conversão dos textos para uma representação numérica. \n",
    "\n",
    "Forma básica: TF (Term Frequency)\n",
    "\n",
    "<img src=\"./img/tf.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x10987 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 67457 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=None,\n",
    "    binary=False,\n",
    "    use_idf=True\n",
    ")\n",
    "tfidf_matrix = vectorizer.fit_transform(df['doc'])\n",
    "\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '000957', '001', '002', '002084', '002086', '003', '003360', '008', '009', '01', '012', '018', '02', '020', '021', '022', '03', '031', '032', '036', '039', '03dez2015', '04', '05', '050617', '052', '056', '05_final', '06', '06h30', '07', '072016', '07h', '07h00', '07h30', '08', '08h', '08h00min', '08h30', '08h30min', '09', '09h', '09h00min', '09h30', '09h30min', '10', '100', '1000', '10024', '106', '107', '109', '10h', '10h00min', '10h30', '10h30m', '10h30min', '10h45mim', '10h45min', '10ª', '10º', '11', '110', '115', '116257', '11h', '11h00', '11h00min', '11h10min', '11h30', '11h30min', '11h40', '11ª', '11º', '12', '120', '121', '125', '1256', '128', '1283', '129', '12h', '12h00min', '12h30', '13', '136', '13h', '13h00', '13h00min', '13h10min', '13h30', '13h30min', '13ª', '14', '140', '141', '143', '145', '146', '149', '14h', '14h00min', '14h30', '14hlocal', '14qualidadedevidaedoambiente', '15', '150', '15h', '15h30', '15h30min', '16', '160', '164', '166', '16h', '16h00min', '16h30', '16h50', '17', '170', '172', '175', '179', '17h', '17h00min', '17h30', '17h30min', '17h45', '17ª', '18', '180', '1827', '185', '189', '18h', '18h00min', '18h15min', '18h30', '18h30min', '18ª', '19', '1909', '191', '1910', '192', '1927', '1927an4vppuglifzxylp9u4ogs', '1932', '1945', '1947', '1972', '1979', '1983', '1984', '1986', '1987', '1992', '1993', '1994', '1995', '1999', '19h', '19h00', '19h00min', '19h15', '19h15min', '19h30', '19h45', '19jifsghun', '19ª', '1_2lgnzzc9ekuu4g5xtn66opwkev5txvea4ivqmh6ycy', '1_uvu7iyigo5d6qfhehvmvop3wxgapk1pdeyr1uvvkqc', '1a', '1aalfne7h4grxa0mkurk7gg4pei5efmmsby54gluw4o4', '1ahcf2vzkiuk9ftljgn_f62esex2wjgww7ivaidltriu', '1asd8wjjwq0ini_tt_jgkzkhepxzdnpagumav8gus5_8', '1azedtlmijk2u', '1bahgg', '1csgcyirajzo4m9hjt2tt_kun6qexqgaybamatk0kky0', '1d4', '1di0b8l8hhcmuicpls6p9vs5ub1xkneyujupfspjia_i', '1dwra7owoaosxovdphuwwhcijahahtqwd88bsiudoyru', '1e09fsvlgbghxb_4d6s9hzqrgt6cur2jbzqingdagxse', '1ed', '1erhcwwkmynbmj0yqejhidawaso2u4u', '1ezktrujmohi', '1faipqlscdlziuyyujafh', '1faipqlscemesh6sdpexovfoqhkvcuckvqnvmnwlchtjgheebxodxohw', '1faipqlscsciawacjjishc53hd', '1faipqlscsve_rzttqs9cnvefg', '1faipqlse5t97v1xbrt2q9xqprrf9gqux7hlo79v6kqkyrlksbryzqtg', '1faipqlsercvcmvhzzn_v0w_8umgdkfjr_qswcmoxydghams29b6ihgq', '1fhbbwdgb1_7jciglamojrwro5uiunebmgadhethfsk0', '1fn8_ymysoveepdturcpigwh8kyuotqi2rqorfs6nhsa', '1fxznjaceqieo_r', '1g5rbhfyjxh6wy3yfqv77_yvng6swnsxoxw3dvezl5c0', '1g9lbd7xhlt9hotp2']\n"
     ]
    }
   ],
   "source": [
    "# Labels das colunas\n",
    "print(vectorizer.get_feature_names()[:200])\n",
    "\n",
    "# Precisamos melhorar o pré-processamento, vieram números e partes de links!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000957</th>\n",
       "      <th>001</th>\n",
       "      <th>002</th>\n",
       "      <th>002084</th>\n",
       "      <th>002086</th>\n",
       "      <th>003</th>\n",
       "      <th>003360</th>\n",
       "      <th>008</th>\n",
       "      <th>...</th>\n",
       "      <th>último</th>\n",
       "      <th>últimos</th>\n",
       "      <th>única</th>\n",
       "      <th>únicas</th>\n",
       "      <th>único</th>\n",
       "      <th>únicos</th>\n",
       "      <th>úteis</th>\n",
       "      <th>útero</th>\n",
       "      <th>útil</th>\n",
       "      <th>útimo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10987 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  000957  001  002  002084  002086  003  003360  008  ...    \\\n",
       "0  0.0  0.0     0.0  0.0  0.0     0.0     0.0  0.0     0.0  0.0  ...     \n",
       "1  0.0  0.0     0.0  0.0  0.0     0.0     0.0  0.0     0.0  0.0  ...     \n",
       "2  0.0  0.0     0.0  0.0  0.0     0.0     0.0  0.0     0.0  0.0  ...     \n",
       "3  0.0  0.0     0.0  0.0  0.0     0.0     0.0  0.0     0.0  0.0  ...     \n",
       "4  0.0  0.0     0.0  0.0  0.0     0.0     0.0  0.0     0.0  0.0  ...     \n",
       "\n",
       "   último  últimos     única  únicas  único  únicos  úteis  útero  útil  útimo  \n",
       "0     0.0      0.0  0.000000     0.0    0.0     0.0    0.0    0.0   0.0    0.0  \n",
       "1     0.0      0.0  0.000000     0.0    0.0     0.0    0.0    0.0   0.0    0.0  \n",
       "2     0.0      0.0  0.000000     0.0    0.0     0.0    0.0    0.0   0.0    0.0  \n",
       "3     0.0      0.0  0.201094     0.0    0.0     0.0    0.0    0.0   0.0    0.0  \n",
       "4     0.0      0.0  0.000000     0.0    0.0     0.0    0.0    0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 10987 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualização da matriz na forma densa (DataFrame)\n",
    "pd.DataFrame(tfidf_matrix.todense(), columns=vectorizer.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similaridade textual\n",
    "\n",
    "Utiliza o espaço vetorial para calcular a distância entre cada texto.\n",
    "\n",
    "<img src=\"http://3.bp.blogspot.com/_tOOi3R89e74/TUeyueig7ZI/AAAAAAAAAJQ/QHL-VLEWook/s1600/vector_space.png\">\n",
    "<strong>Fonte: </strong> http://bitsearch.blogspot.com/2011/01/vector-space-model-for-scoring.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calcula todas as similaridades de cada linha\n",
    "sim = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04840608582716853"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similaridade entre o primeiro e o segundo texto\n",
    "sim[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similaridade entre o primeiro e o centésimo texto\n",
    "sim[0][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'campus barbacena divulga resultado provisório viii simpósio pesquisa inovação campus barbacena divulgou resultado provisório viii simpósio pesquisa inovação estudantes devem ficar atentos observações constam final documento leia documento'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'divulgado edital convocação assembleia centro acadêmico nutrição divulgado edital convocação assembleia centro acadêmico nutrição leia documento'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1].doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'centro memória diaulas abreu reaberto dia 07 agosto centro memória diaulas abreu reaberto visitação novo horário funcionamento 08h 12h 13h 17h agendamentos visitas podem ser realizados contato 32 9 84868411 32 9 82247002 foto rachel santos'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[100].doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similaridade via fuzzywuzzy\n",
    "from Levenshtein import distance\n",
    "\n",
    "distance(\n",
    "    df.iloc[0].doc,\n",
    "    df.iloc[0].doc\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeIA (Léxico para Inferência Adaptada)\n",
    "\n",
    "LeIA (Léxico para Inferência Adaptada) é um fork do léxico e ferramenta para análise de sentimentos VADER (Valence Aware Dictionary and sEntiment Reasoner) adaptado para textos em português, com suporte para emojis e foco na análise de sentimentos de textos expressos em mídias sociais - mas funcional para textos de outros domínios.\n",
    "\n",
    "https://github.com/rafjaa/LeIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A biblioteca preserva a API do VADER, e o texto de entrada não precisa ser pré-processado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from leia import SentimentIntensityAnalyzer \n",
    "\n",
    "s = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.6249, 'neg': 0.0, 'neu': 0.328, 'pos': 0.672}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Análise de texto simples\n",
    "s.polarity_scores('Eu estou feliz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.7964, 'neg': 0.0, 'neu': 0.22, 'pos': 0.78}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Análise de texto com emoji :)\n",
    "s.polarity_scores('Eu estou feliz :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': 0.4404, 'neg': 0.265, 'neu': 0.241, 'pos': 0.494}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Análise de texto com negação\n",
    "s.polarity_scores('Eu não estou feliz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A saída da análise de sentimentos é um dicionário com os seguintes campos:\n",
    "\n",
    "- <code>pos</code>: porcentagem positiva do texto\n",
    "- <code>neg</code>: porcentagem negativa do texto\n",
    "- <code>neu</code>: porcentagem neutra do texto\n",
    "- <code>compound</code>: valor de sentimento geral normalizado, variando de -1 (extremamente negativo) a +1 (extremamente positivo)\n",
    "\n",
    "O valor <code>compound</code> pode ser utilizado para descrever o sentimento predominante no texto, por meio dos limites de valores:\n",
    "\n",
    "- Sentimento positivo: <code>compound >= 0.05</code>\n",
    "- Sentimento negativo: <code>compound <= -0.05</code>\n",
    "- Sentimento neutro: <code>(compound > -0.05) and (compound < 0.05)</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atividade para sala\n",
    "\n",
    "Realizar análise de sentimentos dos dados de um site ou API.\n",
    "\n",
    "<strong>Exemplo:</strong> programa que coleta as notícias do Barbacena Online, analisa seus sentimentos, e exibe o título das notícias, da mais positiva para a mais negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atividade para casa\n",
    "\n",
    "\n",
    "Implementar um sistema de recomendação de notícias para o site do campus: dado o título e o conteúdo de uma nova notícia, indicar as 5 mais semelhantes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
